# General settings
config_dir: null # overwrite by --config-path
inference: false
load: null

# Dataset configuration
dataset:
  data_root: configs/endostreamdepth  # change data path
  resolution: 'base'
  video_length: 5
  train_datasets: [cv3d]  # Comma-separated list of dataset names
  val_datasets: [cv3d]  # Comma-separated list of validation dataset names
  disparity: false

# Training configuration
training:
  batch_size: 4
  workers: 10
  gradient_checkpointing: true
  save_freq: 5000
  val_freq: 100000
  vis_freq: 1000
  total_iters: 20002
  gradient_accumulation: 1
  loss_type: "l1"
  wandb: false
  wandb_name: "experiment"
  start_with_val: false


  # Learning rate configuration
  lr:
    vit: 5.0e-6  # Set to 0 to freeze
    fusion: 1.0e-4  # cross attention modules for hybrid model
    dpt: 5.0e-5
    head: 5.0e-5
    mamba: 1.0e-4
    warmup_steps: 1000

# Model configuration
model:
  # ViT configuration
  vit_size: "vitl"
  patch_size: 14
  attn_class: "MemEffAttention"

  # Mamba configuration
  use_mamba: true
  mamba_type: "add"
  num_mamba_layers: 4
  downsample_mamba: [0.1, 0.1, 0.1, 0.1]
  mamba_pos_embed: null
  mamba_in_dpt_layer: [0, 1, 2, 3]
  mamba_d_conv: 4
  mamba_d_state: 256
  use_hydra: false # https://github.com/goombalab/hydra
  use_transformer_rnn: false
  use_xlstm: false # https://github.com/NX-AI/xlstm

# hybrid model configuration
hybrid_configs:
  use_hybrid: false
  teacher_model_path: null
  teacher_resolution: 490
  layers_to_skip: [1,2,3] # only the 0th index (i.e. path 4 in dpt) is used for fusion
  num_blocks: 4
  mlp_expand: 2
  num_heads: 2


# Evaluation configuration
eval:
  compile: true
  metrics: false
  save_grid: false
  outfolder: "test"
  test_datasets: [cv3d]
  test_dataset_resolution: 'base'
  random_input: null
  out_video: true # whether to save video at all
  out_mp4: true # mp4 if true, gif if false
  save_res: 518
  save_depth_npy: true
  save_vis_map: false
  dummy_timing: false
  large_dir: null
